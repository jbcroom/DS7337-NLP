{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS 7337 - Natural Language Processing\n",
    "\n",
    "### Author: Brandon Croom\n",
    "\n",
    "### Homework: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk and other items\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tag import RegexpTagger\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    " * Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    " * Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. \n",
    " \n",
    " Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Long Sentence Parts of Speech:  [('Every', 'NN'), ('manager', 'NN'), ('should', 'MD'), ('be', 'NN'), ('able', 'NN'), ('to', 'NN'), ('recite', 'NN'), ('at', 'NN'), ('least', 'NN'), ('ten', 'NN'), ('nursery', 'NN'), ('rhymes', 'VBZ'), ('backward', 'NN'), ('.', 'NN')]\nShort Sentence Parts of Speech:  [('Out', 'NN'), ('of', 'NN'), ('the', 'NN'), ('park', 'NN'), ('.', 'NN')]\n"
    }
   ],
   "source": [
    "# Define a random long and short sentence.\n",
    "long_sent_input = \"Every manager should be able to recite at least ten nursery rhymes backward.\"\n",
    "short_sent_input = \"Out of the park.\"\n",
    "\n",
    "# Tokenize the sentences so the taggers will work\n",
    "short_sent_tokens = nltk.word_tokenize(short_sent_input)\n",
    "long_sent_tokens = nltk.word_tokenize(long_sent_input)\n",
    "\n",
    "# we'll use there regular expression tagger first. \n",
    "# Define the patters required for this tagger. Use the inital patterns defined in the NLTK book\n",
    "patterns = [\n",
    "        (r'.*ing$', 'VBG'),               # gerunds\n",
    "        (r'.*ed$', 'VBD'),                # simple past\n",
    "        (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "        (r'.*ould$', 'MD'),               # modals\n",
    "        (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "        (r'.*s$', 'NNS'),                 # plural nouns\n",
    "        (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "        (r'.*', 'NN')                     # nouns (default)\n",
    "       ]\n",
    "\n",
    "reg_expr_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "print(\"Long Sentence Parts of Speech: \", reg_expr_tagger.tag(long_sent_tokens))\n",
    "\n",
    "print(\"Short Sentence Parts of Speech: \", reg_expr_tagger.tag(short_sent_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tagger worked less than perfect with the short sentence due not having enough patterns defined within the tagger to accurately catch all the nuances of the sentence. The default specified for any pattern that does not match a defined regular expression is to default to NN (noun). It can be seen in the case of the short sentence that everything was tagged as NN. This means that the majority of the sentence was placed in the default pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    " * Does it produce the same or different output?\n",
    " * Explain any differences as best you can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Long Sentence Parts of Speech:  [('Every', 'DT'), ('manager', 'NN'), ('should', 'MD'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('recite', 'VB'), ('at', 'IN'), ('least', 'JJS'), ('ten', 'JJ'), ('nursery', 'JJ'), ('rhymes', 'RB'), ('backward', 'RB'), ('.', '.')]\nShort Sentence Parts of Speech:  [('Out', 'IN'), ('of', 'IN'), ('the', 'DT'), ('park', 'NN'), ('.', '.')]\n"
    }
   ],
   "source": [
    "# Now we'll run the same two sentences through the default tagger that it provided by NLTK\n",
    "\n",
    "print(\"Long Sentence Parts of Speech: \", nltk.pos_tag(long_sent_tokens))\n",
    "\n",
    "print(\"Short Sentence Parts of Speech: \", nltk.pos_tag(short_sent_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the default tagger it can be seen that the tagging is much more accurate for both sentences than the regular expression tagger. With respect to the short sentence the default tagger tagged most of the values correctly unlike the regular expression tagger that tagged every token in the sentence as a noun. A similar result can be seen with the long sentence as well. The default tagger was able to identify more tokens with the correct tag and did not default to the noun tag as much as the regular expression tag did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tIn a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    " * Looking at the Penn tag set, manually POS tag the sentence yourself.\n",
    " * Now run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    " * Explain any differences between the two taggers and your manual tagging as much as you can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Regular Expression Tagger Results:  [('By', 'NN'), ('the', 'NN'), ('time', 'NN'), ('President', 'NN'), ('Donald', 'NN'), ('Trump', 'NN'), ('was', 'NNS'), ('gliding', 'VBG'), ('in', 'NN'), ('his', 'NNS'), ('helicopter', 'NN'), ('toward', 'NN'), ('Joint', 'NN'), ('Base', 'NN'), ('Andrews', 'NNS'), ('on', 'NN'), ('Saturday', 'NN'), (',', 'NN'), ('destined', 'VBD'), ('for', 'NN'), ('what', 'NN'), ('he', 'NN'), (\"'d\", 'NN'), ('once', 'NN'), ('hoped', 'VBD'), ('would', 'MD'), ('be', 'NN'), ('a', 'NN'), ('triumphant', 'NN'), ('packed-to-the-rafters', 'NNS'), ('return', 'NN'), ('to', 'NN'), ('the', 'NN'), ('campaign', 'NN'), ('trail', 'NN'), (',', 'NN'), ('things', 'NNS'), ('were', 'NN'), ('already', 'NN'), ('looking', 'VBG'), ('bad', 'NN'), ('.', 'NN')]\nDefault Tagger Results:  [('By', 'IN'), ('the', 'DT'), ('time', 'NN'), ('President', 'NNP'), ('Donald', 'NNP'), ('Trump', 'NNP'), ('was', 'VBD'), ('gliding', 'VBG'), ('in', 'IN'), ('his', 'PRP$'), ('helicopter', 'NN'), ('toward', 'IN'), ('Joint', 'NNP'), ('Base', 'NNP'), ('Andrews', 'NNP'), ('on', 'IN'), ('Saturday', 'NNP'), (',', ','), ('destined', 'VBD'), ('for', 'IN'), ('what', 'WP'), ('he', 'PRP'), (\"'d\", 'MD'), ('once', 'RB'), ('hoped', 'VBN'), ('would', 'MD'), ('be', 'VB'), ('a', 'DT'), ('triumphant', 'JJ'), ('packed-to-the-rafters', 'NNS'), ('return', 'NN'), ('to', 'TO'), ('the', 'DT'), ('campaign', 'NN'), ('trail', 'NN'), (',', ','), ('things', 'NNS'), ('were', 'VBD'), ('already', 'RB'), ('looking', 'VBG'), ('bad', 'JJ'), ('.', '.')]\n"
    }
   ],
   "source": [
    "news_sentence = \"By the time President Donald Trump was gliding in his helicopter toward Joint Base Andrews on Saturday, destined for what he'd once hoped would be a triumphant packed-to-the-rafters return to the campaign trail, things were already looking bad.\"\n",
    "\n",
    "news_sent_tokens = nltk.word_tokenize(news_sentence)\n",
    "\n",
    "print(\"Regular Expression Tagger Results: \", reg_expr_tagger.tag(news_sent_tokens))\n",
    "print(\"Default Tagger Results: \", nltk.pos_tag(news_sent_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual tagging:\n",
    "By - IN\n",
    "the - DT\n",
    "time - NN\n",
    "President - NNP\n",
    "Donald - NNP\n",
    "Trump - NNP\n",
    "was - VBD\n",
    "gliding - VBG\n",
    "in - IN\n",
    "his - PRPS\n",
    "helicopter - NN\n",
    "toward - IN\n",
    "Joint - NNP\n",
    "Base - NNP\n",
    "Andrews - NNP\n",
    "on - IN\n",
    "Saturday - NNP\n",
    ", - ,\n",
    "destined - VBN\n",
    "for - IN\n",
    "what - NP\n",
    "he - PRP\n",
    "'d - VBD\n",
    "once - RB\n",
    "hoped - VBN\n",
    "would - MD\n",
    "be - VB\n",
    "a - DT\n",
    "trimphant - JJ\n",
    "packed-to-the-rafters - NNS\n",
    "return - VBP\n",
    "to - TO\n",
    "the - BT\n",
    "campaign - NN\n",
    "trail - NN\n",
    ", - ,\n",
    "things - NNS\n",
    "were - VBD\n",
    "already - RB\n",
    "looking - VBG\n",
    "bad - JJ\n",
    ". - .\n",
    "\n",
    "\n",
    "### Analysis:\n",
    "In matching the manual tagging to the regular expression tagger and the NLTK default tagger, we see that the default tagger and the manual tagging were almost identical. This was not the case with the regular expression tagger and the manual tagging effort. For example, in the manual tagging effort the first word in the sentence \"By\" was tagged as a preposition. In the regular expression tagger it was tagged as a noun due to no pattern matching this value. The default tagger matched the manual tagging effort. Prepositional phrases and determinants seem to be the largest difference between the taggers. The regular expression tagger does a poor job with these token types where the default tagger and the manual tagging effort both take these types into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit36305f9ad6c54384bcdc334bae9910c8",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}