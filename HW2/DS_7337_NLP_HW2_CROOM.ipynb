{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS 7337 - Natural Language Processing\n",
    "\n",
    "### Author: Brandon Croom\n",
    "\n",
    "### Homework: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk and other items\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.book import *\n",
    "from nltk.corpus import words\n",
    "\n",
    "# define the text word count\n",
    "def text_word_count(text_data):\n",
    "    return len(text_data)\n",
    "\n",
    "# define the text vocabulary size\n",
    "def text_vocab_size(text_data):\n",
    "    return len(set(text_data))\n",
    "\n",
    "# define a method that will get us all words in the english language\n",
    "def english_lang_words():\n",
    "    word_list = words.words()\n",
    "    return len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\tIn Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. (Various methods will be discussed in the live session.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.07159029467423628"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# define the vocabulary size method. Filter out everything that is not alpha numeric and make it all lower case.\n",
    "# We'll normalize using the size calculation of the vocabulary and divide by the total number of the vocabulary size. Using the standard normalization formula (x - min(x) / (max(x) - min(x))). Assuming min(x) = 0 (this is the fewest number of words possible) this minimizes to x/max(x) where x=size of the text after cleansing and max(x) = the full size of the english language \n",
    "def vocab_size(text):\n",
    "    size = len(set(word.lower() for word in text if word.isalpha()))\n",
    "    return size/english_lang_words()\n",
    "    #text_vocab_size(text)\n",
    "\n",
    "vocab_size(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tAfter consulting section 3.2 in chapter 1 of Bird-Klein, create a method for scoring the long-word vocabulary size of a text, and likewise normalize (and explain) the scoring as in step 1 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8.025817788591511e-05"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# define the long word score function. We'll allow the user to input the word length and the number of times the word should occur in the text before it's counted. We'll normalize by \n",
    "# dividing the length of the long words by the total number of words in the text provided. Using the standard normalization formula (x - min(x) / (max(x) - min(x))). Assuming min(x) = 0 (this is the fewest number of words possible) this minimizes to x/max(x) where x=size of the text after cleansing and max(x) = the full size of the english language \n",
    "def long_word_score(text, word_len=7, word_freq=7):\n",
    "    fdist = FreqDist(text)\n",
    "    size = sorted(word for word in set(text) if len(word) > word_len and fdist[word] > word_freq)\n",
    "    return len(size)/english_lang_words()\n",
    "\n",
    "long_word_score(text5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tNow create a “text difficulty score” by combining the lexical diversity score from homework 1, and your normalized score of vocabulary size and long-word vocabulary size, in equal weighting. Explain what you see when this score is applied to same graded texts you used in homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Text Difficulty Score The Ontario Readers: Third Book:  0.04969884364250884\nText Difficulty Score The Ontario Readers: Fourth Book:  0.05454543644267229\nText Difficulty Score The Ontario Readers: The High School Book:  0.05382365014314133\n"
    }
   ],
   "source": [
    "#HW 1 lexical diversity function\n",
    "def lexical_diversity(text_data):\n",
    "    word_count = text_word_count(text_data)\n",
    "    vocab_size = text_vocab_size(text_data)\n",
    "    diversity_score = vocab_size / word_count\n",
    "    return diversity_score\n",
    "\n",
    "# text difficulty score function. Create a weighted average function. Allow the user to input specific weights for\n",
    "# lexical diversity, word score, and vocabulary size. Defaults for all are 1 to keep the weights equal\n",
    "def text_diff_score(text, lex_div_weight=1,word_score_weight=1,vocab_size_weight=1):\n",
    "    lex_div = lexical_diversity(text)*lex_div_weight\n",
    "    word_score = long_word_score(text) * word_score_weight\n",
    "    vsize = vocab_size(text) * vocab_size_weight\n",
    "\n",
    "    return (lex_div + word_score + vsize)/3\n",
    "    \n",
    "\n",
    "# load the same corpus used in HW1\n",
    "corpus_root = \"C://RAI//DS7337-NLP//HW1//corpus\"\n",
    "file_pattern = r\".*/*.*\\.txt\"\n",
    "ptb = PlaintextCorpusReader(corpus_root,file_pattern)\n",
    "ptb.fileids()\n",
    "\n",
    "# print out the new text difficulty scores\n",
    "print(\"Text Difficulty Score The Ontario Readers: Third Book: \",text_diff_score(ptb.words(ptb.fileids()[0])))\n",
    "print(\"Text Difficulty Score The Ontario Readers: Fourth Book: \",text_diff_score(ptb.words(ptb.fileids()[1])))\n",
    "print(\"Text Difficulty Score The Ontario Readers: The High School Book: \",text_diff_score(ptb.words(ptb.fileids()[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Using the text difficult score above, we see that this text difficulty score follows a similar pattern to just looking at lexical diversity for the texts, like in HW1. It's a bit counter intuitive. The text designed for high school has a score of 0.053, which is lower than the book for fourth grade. We would expect that the high school book would have the higher of the scores when compared to books for third and fourth graders. The text difficulty scores for the third and fourth grade books show, they are close in difficulty, but do have a separation which would be indicative of the grade change.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit36305f9ad6c54384bcdc334bae9910c8",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}