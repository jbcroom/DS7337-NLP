{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS 7337 - Natural Language Processing\n",
    "\n",
    "### Author: Brandon Croom\n",
    "\n",
    "### Homework: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk and other items\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tCompare your given name with your nickname (if you donâ€™t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "*\tWhat is the edit distance between your nickname and your given name?\n",
    "*\tWhat is the percentage string match between your nickname and your given name?\n",
    "\n",
    "Show your work for both calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Edit Distance - Custom function:  0\nEdit Distance - NLTK function:  0\nPercent Match:  100\n"
    }
   ],
   "source": [
    "def edit_dist(str1, str2):\n",
    "    # check the string lengths. If they differ calculate the difference between them\n",
    "    if (len(str1) > len(str2)):\n",
    "        diff = len(str1) - len(str2)\n",
    "        str1[:diff]\n",
    "    elif (len(str2) > len(str1)):\n",
    "        diff = len(str2) - len(str1)\n",
    "        str2[:diff]\n",
    "    else:\n",
    "        diff = 0\n",
    "\n",
    "    # loop through str1 and compare characters between str1 and str2 to determine\n",
    "    # differences in the strings. Check to ensure we don't index incorrectly when the \n",
    "    # string lengths are different\n",
    "    for i in range(len(str1)):\n",
    "        if (i >= len(str1)):\n",
    "            break\n",
    "\n",
    "        if (i >= len(str2)):\n",
    "            break\n",
    "\n",
    "        if (str1[i] != str2[i]):\n",
    "            diff +=1\n",
    "\n",
    "    return diff\n",
    "\n",
    "def percent_diff(str1,str2,edit_dist):\n",
    "\n",
    "    # if we get 0 as an edit_distance then we have no difference\n",
    "    if edit_dist == 0:\n",
    "        return 0\n",
    "\n",
    "    # check to find the longest word of the strings and calculate the percentage between\n",
    "    # the longest word and the edit distance\n",
    "    if (len(str1) > len(str2)):\n",
    "        return (edit_dist / len(str1))\n",
    "    elif (len(str2) > len(str1)):\n",
    "        return (edit_dist / len(str2))\n",
    "    else:\n",
    "        return (edit_dist / len(str1))\n",
    "\n",
    "\n",
    "given_name = \"Brandon\"\n",
    "nickname = \"B\"\n",
    "\n",
    "# check the custom function for edit distance calculation\n",
    "cust_edit_dist = edit_dist(given_name,nickname)\n",
    "\n",
    "# use the NLTK edit distance function to ensure our custom calculations are correct\n",
    "nltk_edit_dist = nltk.edit_distance(given_name,nickname)\n",
    "\n",
    "# determine the percentage difference in matching\n",
    "percent_diff = percent_diff(given_name,nickname,cust_edit_dist)\n",
    "\n",
    "print(\"Edit Distance - Custom function: \", edit_dist(given_name,nickname))\n",
    "print(\"Edit Distance - NLTK function: \", nltk.edit_distance(given_name,nickname))\n",
    "print(\"Percent Match: \", (1 - percent_diff)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tFind a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The initial sentence:  Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\n\nThe filtered sentence:  ['Mr.', 'Mrs.', 'Dursley', ',', 'number', 'four', ',', 'Privet', 'Drive', ',', 'proud', 'say', 'perfectly', 'normal', ',', 'thank', 'much', '.', 'They', 'last', 'people', \"'d\", 'expect', 'involved', 'anything', 'strange', 'mysterious', ',', \"n't\", 'hold', 'nonsense', '.']\n"
    }
   ],
   "source": [
    "Initial_Sentence = \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\"\n",
    "\n",
    "def clean_sent(text):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "    word_tokens = word_tokenize(text) \n",
    "  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "  \n",
    "    filtered_sentence = [] \n",
    "  \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "\n",
    "    return filtered_sentence\n",
    "\n",
    "Filtered_Sentence = clean_sent(Initial_Sentence)\n",
    "print(\"The initial sentence: \", Initial_Sentence)\n",
    "print(\"\")\n",
    "print(\"The filtered sentence: \", Filtered_Sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After passing the filtered sentence to my family member, they were able to determine the exact book \"Harry Potter and the Sorcerer's Stone\" as well as the exact chapter, Chapter 1. They even estimated that these were the first sentences of the book. I think they were able to determine the book, chapter and location of the sentence for two key reasons. First, they were extremely familiar with the book having read it multiple times. Secondly, in looking at the removal of stop words there isn't much change in the sentence. There are key words that remain in the sentence that provide plenty of context for those familiar with the story. Had this been a book that my family member was less familiar with I believe it would have been harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tRun one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Initial Text:\n\nmr.\nand\nmrs.\ndursley\n,\nof\nnumber\nfour\n,\nprivet\ndrive\n,\nwere\nproud\nto\nsay\nthat\nthey\nwere\nperfectli\nnormal\n,\nthank\nyou\nveri\nmuch\n.\nthey\nwere\nthe\nlast\npeopl\nyou\n'd\nexpect\nto\nbe\ninvolv\nin\nanyth\nstrang\nor\nmysteri\n,\nbecaus\nthey\njust\ndid\nn't\nhold\nwith\nsuch\nnonsens\n.\nNone\n\nFiltered Text:\n\nmr.\nmrs.\ndursley\n,\nnumber\nfour\n,\nprivet\ndrive\n,\nproud\nsay\nperfectli\nnormal\n,\nthank\nmuch\n.\nthey\nlast\npeopl\n'd\nexpect\ninvolv\nanyth\nstrang\nmysteri\n,\nn't\nhold\nnonsens\n.\nNone\n"
    }
   ],
   "source": [
    "def StemViaPorter(text):\n",
    "    ps = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    for w in words:\n",
    "        print(ps.stem(w))\n",
    "\n",
    "def StemViaPorterTokenized(text):\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for w in text:\n",
    "        print(ps.stem(w))\n",
    "\n",
    "print(\"Initial Text:\")\n",
    "print(\"\")\n",
    "print(StemViaPorter(Initial_Sentence))\n",
    "print(\"\")\n",
    "print(\"Filtered Text:\")\n",
    "print(\"\")\n",
    "print(StemViaPorterTokenized(Filtered_Sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looking at the stemmer output we see a few items. First for the initial text we see that about 5 words don't look like they are stemmed as well as they could be. For example, perfectly stemmed to perfectli. The better stem for this would have been perfect. Making a quick calculation, these 5 items result in about 2% of the total words, leaving about 98% of the words having stems that make sense. These calculations are based on the 5 poorly stemmed words over the 262 words in the sentences\n",
    "\n",
    "For the filtered sentence we still see the same 5 items that don't look like they stemmed well. Using another example: Anything stemmed to anyth. It makes it difficult to tell what that stem really is. Using the same values, this time with only a 32 word length, we see approximately 16% stemmed incorrectly and about 84% stemmed correctly. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit36305f9ad6c54384bcdc334bae9910c8",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}